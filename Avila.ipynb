{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndioP/Projeto-AM/blob/main/Avila.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AkUTfpA_inV_"
      },
      "source": [
        "# Projeto 1 de Aprendizado de Máquina\n",
        "## Grupo\n",
        "- João Victor de Lima Peixoto\n",
        "- José Douglas Pontes Silva\n",
        "- Marcos Heitor Carvalho de Oliveira\n",
        "- Mikael Vidal da Silva\n",
        "\n",
        "# Introdução\n",
        "O projeto da cadeira de aprendizado de máquina visa aplicar as diferentes técnicas aprendidas na disciplina para fazer uma análise exploratoria sobre a `precisão (precision)`, `cobertura (recall)` e `f1-score` presentes no uso de cada algoritmo estudado em um `dataset` do mundo real.\n",
        "\n",
        "Os algoritmos aprendidos na cadeira e testados no projeto foram:\n",
        "- Árvores de Decisões\n",
        "- Bayesiano Ingenuo\n",
        "- Regressão Logistica\n",
        "- K Vizinhos\n",
        "\n",
        ", onde cada algoritmo apresenta parâmetros e logicas próprias que serão discutidas na fundamentação teórica deste relatório.\n",
        "\n",
        "O conjunto de dados testado no projeto foi o `Avila Data Set`. Em resumo, esse conjunto de dados foi extraido através de 800 imagens da Biblia de Avila, uma cópia em latim da Biblia produzida no século XII em um local entre a Itália e a Espanha. No capítulo \"Conjunto de dados\", faremos uma descrição mais ampla de como esse dataset é dividido e também das suas features.\n",
        "\n",
        "Por fim, mostraremos os resultados e conclusões obtidas dos nossos experimentos.\n",
        "\n",
        "# Objetivos\n",
        "\n",
        "O objetivo geral do projeto é explorar os algoritmos aprendidos na cadeira de Aprendizagem de Máquina. Essa objetivo geral engloba os seguintes objetivos especificos:\n",
        "\n",
        "- I. Explorar o conjunto de dados de `Avila` e verificar as features relevantes para cada método utilizado.\n",
        "- II. Realizar o treinamento e classificação de cada um dos algoritmos aprendidos utilizando o `Avila Data Set`.\n",
        "- III. Realizar uma analise exploratoria de mudanças dps hiper-parametros de cada algoritmo para buscar valores melhores de `precision`, `recall` e `f1-score`.\n",
        "\n",
        "# Fundamentação Teórica\n",
        "\n",
        "Nesse cápitulo abordaremos alguns dos fundamentos básicos para que o leitor possa entender o projeto. Inicialmente falaremos sobre as métricas usadas para avaliar cada modelo e em seguida falaremos sobre cada modelo em si.\n",
        "\n",
        "## Métricas\n",
        "\n",
        "Em geral, quando estamos trabalhando com modelos de classificação, precisamos de algumas métricas para avaliar se a performance de um modelo é melhor do que a de outro modelo ao realizar uma classificação. Nesse contexto, `precision`, `recall` e `f1-score` servem como essas métricas para prover o quão bem um modelo é capaz de prever corretamente a classificação de uma instância com sua classe real. Além disso, essas métricas nos ajudam a comparar diferentes modelos ou parâmetros usados em algum classificador para otimizar sua performance. \n",
        "\n",
        "### Precision\n",
        "\n",
        "A métrica de precisão (ou `precision`) mede a proporção de predições verdadeiras sobre todas as predições positivas feitas pelo modelo. A precisão é calculada como na fórmula abaixo:\n",
        "\n",
        "<img src=\"http://www.sciweavers.org/tex2img.php?eq=%20%5Cfrac%7BTP%7D%7BTP%20%2B%20FP%7D%20&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0\" align=\"center\" border=\"0\" alt=\" \\frac{TP}{TP + FP} \" width=\"67\" height=\"43\" />\n",
        "\n",
        ", onde `TP` é número de predições positivas enquando `FP` é o número de predições falso-positivas. Uma precisão alta indica que o modelo é bom em indentificar instâncias e tem uma taxa baixa de falso-positivos.\n",
        "\n",
        "### Recall \n",
        "\n",
        "A métrica de cobertura (ou `recall`) mede a proporção de precições verdadeiras sobre todas as instâncias verdadeiramente positivas nos dados. A cobertura é calculada como na fórmula abaixo:\n",
        "\n",
        "<img src=\"http://www.sciweavers.org/tex2img.php?eq=%20%5Cfrac%7BTP%7D%7BTP%20%2B%20FN%7D%20&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0\" align=\"center\" border=\"0\" alt=\" \\frac{TP}{TP + FN} \" width=\"69\" height=\"43\" />\n",
        "\n",
        ", onde `TP` é número de predições positivas enquando `FN` é o número de predições falso-negativas. Uma cobertura alta indica que o modelo é bom em indentificar todas as intâncias positivas e tem uma taxa baixa de falso-negativos.\n",
        "\n",
        "### F1-Score\n",
        "\n",
        "A métrica `f1-score` combina tanto a precisão como a cobertura em uma unica métrica. O `f1-score` pode ser calculada da seguinte forma:\n",
        "\n",
        "<img src=\"http://www.sciweavers.org/tex2img.php?eq=%202%20%2A%20%5Cfrac%7Bprecision%20%2A%20recall%7D%7Bprecision%20%2B%20recall%7D%20&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0\" align=\"center\" border=\"0\" alt=\" 2 * \\frac{precision * recall}{precision + recall} \" width=\"187\" height=\"47\" />\n",
        "\n",
        "Essa métrica serve para avaliar a performance de um modelo onde ambas precisão e cobertura são desejadas.\n",
        "\n",
        "## Algoritmos\n",
        "\n",
        "Dentro do assunto de aprendizado de máquina, os algoritmos que nós aprendemos servem como modelos de classificação. Esses modelos de classificação servem para prever uma classe categorica sobre uma instância de entrada levando em consideração suas `features`, ou parâmetros de entrada.\n",
        "\n",
        "No caso do projeto, faremos um aprendizado supervisionado, onde usaremos um conjunto de dados já rotulados com a classe correta na entrada para treinar os modelos de classifação. Com isso, os modelos serão capazes de predizer a classe de dados ainda não vistos. \n",
        "\n",
        "Existem muitos tipos de modelos de classificação na literatura. Entraremos agora em detalhe sobre os modelos de classificação usados no projeto.\n",
        "\n",
        "### Decision Tree Classifier\n",
        "\n",
        "### Naive Bayes\n",
        "\n",
        "### Logistic Regression\n",
        "\n",
        "### K-Neighbors\n",
        "\n",
        "# Conjunto de Dados\n",
        "\n",
        "A analisa paleografica do manuscrito indicou a presença de 12 escrivãos responsáveis pela copia. A quantidade de páginas escritas por cada escrivão não é igual.\n",
        "\n",
        "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows.\n",
        "\n",
        "The prediction task consists in associating each pattern to one of the 12 copyists (labeled as: A, B, C, D, E, F, G, H, I, W, X, Y).\n",
        "The data have has been normalized, by using the Z-normalization method, and divided in two data sets: a training set containing 10430 samples, and a test set  containing the 10437 samples.\n",
        "\n",
        "Os dados do projeto AVILA são referentes as informações extraidas das imagens das páginas copiadas da biblía de AVILA.\n",
        "As CLASSES de [A, B, C, D, E, F, G, H, I, W, X, Y] fazem referência a qual copiador foi responsavel por aquele trecho/página\n",
        "Então, a ideia é conseguir criar um bom classificador, que consiga por meio das informações extraidas dos trechos das páginas [F1,F2,F3,F4,F5,F6,F6,F7,F8,F9,F10] consiga-se identificar quem foi o copiador responsavél\n",
        "\n",
        "\n",
        "# Metodologia\n",
        "\n",
        "A metodologia utilizada neste projeto se concentra em 3 formas de desenvolvimento para cada método.\n",
        "- 1. Realizar o treinamento e classificação utilizando os valores default dos respectivos métodos\n",
        "- 2. Realizar uma analise exploratoria de mudanças de hiper-parametros para buscar valores melhores de precision | recall | f1-score\n",
        "- 3. Utilizar do OPTUNA, ferramenta que automatiza o processo de testagem de hiper-parametros para um determinado modelo. \n",
        "\n",
        "# Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fowlwl44XDu",
        "outputId": "2c39c483-29dc-495b-fdfe-6d3601a1fab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Projeto-AM' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IndioP/Projeto-AM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGJmsO_OYf7A"
      },
      "source": [
        "## Import's iniciais do projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iorlHYAJKVxz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8HjT3TMJzQK"
      },
      "outputs": [],
      "source": [
        "names = ['F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','Class']\n",
        "df = pd.read_csv(\"Projeto-AM/avila-tr.txt\",names = names)\n",
        "df_ts = pd.read_csv(\"Projeto-AM/avila-ts.txt\",names=names)\n",
        "X_test = df_ts.drop(\"Class\",axis=1)\n",
        "y_test = df_ts[\"Class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Wz9UqFngKnOs",
        "outputId": "f82503c2-7a29-49c3-b54a-a37832b37ded"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5b7492b2-845c-44ca-b21d-098b8b2ca0f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.266074</td>\n",
              "      <td>-0.165620</td>\n",
              "      <td>0.320980</td>\n",
              "      <td>0.483299</td>\n",
              "      <td>0.172340</td>\n",
              "      <td>0.273364</td>\n",
              "      <td>0.371178</td>\n",
              "      <td>0.929823</td>\n",
              "      <td>0.251173</td>\n",
              "      <td>0.159345</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.130292</td>\n",
              "      <td>0.870736</td>\n",
              "      <td>-3.210528</td>\n",
              "      <td>0.062493</td>\n",
              "      <td>0.261718</td>\n",
              "      <td>1.436060</td>\n",
              "      <td>1.465940</td>\n",
              "      <td>0.636203</td>\n",
              "      <td>0.282354</td>\n",
              "      <td>0.515587</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.116585</td>\n",
              "      <td>0.069915</td>\n",
              "      <td>0.068476</td>\n",
              "      <td>-0.783147</td>\n",
              "      <td>0.261718</td>\n",
              "      <td>0.439463</td>\n",
              "      <td>-0.081827</td>\n",
              "      <td>-0.888236</td>\n",
              "      <td>-0.123005</td>\n",
              "      <td>0.582939</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.031541</td>\n",
              "      <td>0.297600</td>\n",
              "      <td>-3.210528</td>\n",
              "      <td>-0.583590</td>\n",
              "      <td>-0.721442</td>\n",
              "      <td>-0.307984</td>\n",
              "      <td>0.710932</td>\n",
              "      <td>1.051693</td>\n",
              "      <td>0.594169</td>\n",
              "      <td>-0.533994</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.229043</td>\n",
              "      <td>0.807926</td>\n",
              "      <td>-0.052442</td>\n",
              "      <td>0.082634</td>\n",
              "      <td>0.261718</td>\n",
              "      <td>0.148790</td>\n",
              "      <td>0.635431</td>\n",
              "      <td>0.051062</td>\n",
              "      <td>0.032902</td>\n",
              "      <td>-0.086652</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b7492b2-845c-44ca-b21d-098b8b2ca0f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b7492b2-845c-44ca-b21d-098b8b2ca0f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b7492b2-845c-44ca-b21d-098b8b2ca0f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         F1        F2        F3        F4        F5        F6        F7  \\\n",
              "0  0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
              "1  0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
              "2 -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
              "3  0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
              "4  0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
              "\n",
              "         F8        F9       F10 Class  \n",
              "0  0.929823  0.251173  0.159345     A  \n",
              "1  0.636203  0.282354  0.515587     A  \n",
              "2 -0.888236 -0.123005  0.582939     A  \n",
              "3  1.051693  0.594169 -0.533994     A  \n",
              "4  0.051062  0.032902 -0.086652     F  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wKLthUdYs0l"
      },
      "source": [
        "### Separando o conjunto de treinamento em TREINO 80% | VALIDAÇÃO 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2INz5S4JK_1N"
      },
      "outputs": [],
      "source": [
        "X_train,X_valid,y_train,y_valid = train_test_split(df.drop(\"Class\",axis=1), df[\"Class\"],test_size=0.2,random_state=2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TIm0U14LQZN",
        "outputId": "ada3099f-d53a-4bbc-b106-ef8d5ecb9919"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8344, 10), (8344,), (2086, 10), (2086,))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape,y_train.shape,X_valid.shape,y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nxvz47BY26V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xKeOyElY1Kf"
      },
      "source": [
        "## Primeira análise dos modelos com valores default's dos métodos utilizados pelo Scikit Learn\n",
        "- Decisition Tree\n",
        "- Gaussian NB\n",
        "- LOgistic Regression\n",
        "- KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_DvgdguY5Yy"
      },
      "outputs": [],
      "source": [
        "models = [DecisionTreeClassifier(), GaussianNB(), Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(max_iter=10000))]), KNeighborsClassifier()]\n",
        "models_names = [\"DecisionTreeClassifier\", \"GaussianNB\", \"LogisticRegression\", \"KNeighborsClassifier\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcFB1qdgMEzv",
        "outputId": "157e8456-51a3-4ac7-fb17-c4263a95727c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model:  DecisionTreeClassifier\n",
            "Accuracy:  0.9741131351869607\n",
            "Precision:  0.9745985939931646\n",
            "Recall:  0.9741131351869607\n",
            "F1-score:  0.9742471186418911\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Model:  GaussianNB\n",
            "Accuracy:  0.28044103547459254\n",
            "Precision:  0.4869461008434287\n",
            "Recall:  0.28044103547459254\n",
            "F1-score:  0.31269471946758487\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Model:  LogisticRegression\n",
            "Accuracy:  0.5522531160115053\n",
            "Precision:  0.8055085318695356\n",
            "Recall:  0.5522531160115053\n",
            "F1-score:  0.631349791534737\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Model:  KNeighborsClassifier\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7157238734419943\n",
            "Precision:  0.7428505624498204\n",
            "Recall:  0.7157238734419943\n",
            "F1-score:  0.7225385508602775\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for model,name in zip(models,models_names):\n",
        "  print(f'\\nModel: ',name)\n",
        "  clf = model\n",
        "  clf.fit(X_train,y_train)\n",
        "  \n",
        "  print(\"Accuracy: \",clf.score(X_valid,y_valid))\n",
        "  \n",
        "  pred = clf.predict(X_valid)\n",
        "  print(\"Precision: \",precision_score(pred,y_valid,average=\"weighted\"))\n",
        "  print(\"Recall: \",recall_score(pred,y_valid,average=\"weighted\"))\n",
        "  print(\"F1-score: \",f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9VuLxEPQuxL",
        "outputId": "30cb9329-ebb2-415b-82eb-6ca06b3b4e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision:  0.7552854027850691\n",
            "Recall:  0.7311487975471879\n",
            "F1-score:  0.7369839317135863\n"
          ]
        }
      ],
      "source": [
        "def check_test(clf,X_test,y_test):\n",
        "  pred = clf.predict(X_test)\n",
        "  print(\"Precision: \",precision_score(pred,y_test,average=\"weighted\"))\n",
        "  print(\"Recall: \",recall_score(pred,y_test,average=\"weighted\"))\n",
        "  print(\"F1-score: \",f1_score(pred,y_test,average=\"weighted\"))\n",
        "\n",
        "check_test(clf,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkZFB8s8SzCL",
        "outputId": "15bd57c2-4c3e-47ef-cfbc-72bdc99df929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.12.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykbMCvn_8SDY"
      },
      "source": [
        "# DecisionTreeClassifier parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqHEoNio6Y9Z"
      },
      "outputs": [],
      "source": [
        "criterion = \"gini\" #What is the criterion used for the split\n",
        "#There is an scientific paper comparing gini and entropy and they diverge in only 2% of the cases, but entropy is a little slower because of logarithm\n",
        "\n",
        "splitter = \"best\" #The strategy used to choose the split at each node\n",
        "#If the model is suffering from overfitting we can change it to random, to avoid this fate\n",
        "\n",
        "max_depth = None #can be None to go forever till purity beeing achieved\n",
        "\n",
        "min_samples_split = 2 #if int, it is the minimal number to make a split\n",
        "                      #if float, it is the min_samples_split * n_samples\n",
        "\n",
        "min_samples_leaf = 1 #int, float\n",
        "\n",
        "#min_weight_fraction_leaf = \n",
        "\n",
        "max_features = None #there are few features, so I think"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMxekoKYHO3g",
        "outputId": "2a773b2f-57a4-443c-c8e0-06960ec1d77b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-03-05 14:42:31,615]\u001b[0m A new study created in memory with name: no-name-a759c063-2c38-436e-bee5-47d53eecddad\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:31,707]\u001b[0m Trial 0 finished with value: 0.8841244291729367 and parameters: {'min_samples_split': 39, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.8841244291729367.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:31,803]\u001b[0m Trial 1 finished with value: 0.9170424581061433 and parameters: {'min_samples_split': 25, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.9170424581061433.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:31,900]\u001b[0m Trial 2 finished with value: 0.9471279855591596 and parameters: {'min_samples_split': 15, 'min_samples_leaf': 22}. Best is trial 2 with value: 0.9471279855591596.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,020]\u001b[0m Trial 3 finished with value: 0.9503280310832801 and parameters: {'min_samples_split': 13, 'min_samples_leaf': 26}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,180]\u001b[0m Trial 4 finished with value: 0.8536972179229775 and parameters: {'min_samples_split': 48, 'min_samples_leaf': 25}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,310]\u001b[0m Trial 5 finished with value: 0.8534188114979873 and parameters: {'min_samples_split': 47, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,406]\u001b[0m Trial 6 finished with value: 0.890729740559113 and parameters: {'min_samples_split': 36, 'min_samples_leaf': 21}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,498]\u001b[0m Trial 7 finished with value: 0.8647611478643226 and parameters: {'min_samples_split': 47, 'min_samples_leaf': 27}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,587]\u001b[0m Trial 8 finished with value: 0.8896521566810252 and parameters: {'min_samples_split': 36, 'min_samples_leaf': 26}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,678]\u001b[0m Trial 9 finished with value: 0.894078685533184 and parameters: {'min_samples_split': 34, 'min_samples_leaf': 28}. Best is trial 3 with value: 0.9503280310832801.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,797]\u001b[0m Trial 10 finished with value: 0.9713983299541559 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9713983299541559.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:32,909]\u001b[0m Trial 11 finished with value: 0.9723446684963984 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.9723446684963984.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:33,041]\u001b[0m Trial 12 finished with value: 0.9760114064336336 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9760114064336336.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:33,188]\u001b[0m Trial 13 finished with value: 0.9741945272574176 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.9760114064336336.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:33,351]\u001b[0m Trial 14 finished with value: 0.9546368278069198 and parameters: {'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.9760114064336336.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:33,512]\u001b[0m Trial 15 finished with value: 0.9380140557434806 and parameters: {'min_samples_split': 18, 'min_samples_leaf': 14}. Best is trial 12 with value: 0.9760114064336336.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:33,708]\u001b[0m Trial 16 finished with value: 0.9670565197018924 and parameters: {'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.9760114064336336.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:33,911]\u001b[0m Trial 17 finished with value: 0.9314651662019661 and parameters: {'min_samples_split': 21, 'min_samples_leaf': 14}. Best is trial 12 with value: 0.9760114064336336.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:34,251]\u001b[0m Trial 18 finished with value: 0.9770056355787458 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:34,424]\u001b[0m Trial 19 finished with value: 0.960860027692842 and parameters: {'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:34,583]\u001b[0m Trial 20 finished with value: 0.9132057500065504 and parameters: {'min_samples_split': 28, 'min_samples_leaf': 11}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:34,748]\u001b[0m Trial 21 finished with value: 0.9737378482935788 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:34,923]\u001b[0m Trial 22 finished with value: 0.9714110738642816 and parameters: {'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:35,091]\u001b[0m Trial 23 finished with value: 0.9719009071707865 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:35,254]\u001b[0m Trial 24 finished with value: 0.974177437375959 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:35,429]\u001b[0m Trial 25 finished with value: 0.9457991295577389 and parameters: {'min_samples_split': 16, 'min_samples_leaf': 17}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:35,608]\u001b[0m Trial 26 finished with value: 0.9541746859755718 and parameters: {'min_samples_split': 11, 'min_samples_leaf': 7}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:35,777]\u001b[0m Trial 27 finished with value: 0.9300254529804286 and parameters: {'min_samples_split': 21, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:35,952]\u001b[0m Trial 28 finished with value: 0.9705699547282572 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 11}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:36,120]\u001b[0m Trial 29 finished with value: 0.953202219030853 and parameters: {'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:36,248]\u001b[0m Trial 30 finished with value: 0.8723516475900003 and parameters: {'min_samples_split': 43, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:36,352]\u001b[0m Trial 31 finished with value: 0.9728383291127087 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:36,463]\u001b[0m Trial 32 finished with value: 0.9680312171029787 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:36,721]\u001b[0m Trial 33 finished with value: 0.9732094748999212 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:36,896]\u001b[0m Trial 34 finished with value: 0.9628107860156456 and parameters: {'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:37,084]\u001b[0m Trial 35 finished with value: 0.9719212601384409 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:37,273]\u001b[0m Trial 36 finished with value: 0.9498918200264828 and parameters: {'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:37,471]\u001b[0m Trial 37 finished with value: 0.9072005730533447 and parameters: {'min_samples_split': 29, 'min_samples_leaf': 30}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:37,702]\u001b[0m Trial 38 finished with value: 0.9727995189568847 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 18}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:37,851]\u001b[0m Trial 39 finished with value: 0.9532924377403 and parameters: {'min_samples_split': 12, 'min_samples_leaf': 7}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:38,008]\u001b[0m Trial 40 finished with value: 0.9428435221106475 and parameters: {'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.9770056355787458.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:38,229]\u001b[0m Trial 41 finished with value: 0.9774722657465068 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:38,414]\u001b[0m Trial 42 finished with value: 0.9661589716154518 and parameters: {'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:38,634]\u001b[0m Trial 43 finished with value: 0.9742794745604325 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:38,825]\u001b[0m Trial 44 finished with value: 0.9695067130903471 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 22}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:39,032]\u001b[0m Trial 45 finished with value: 0.9723412739666746 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:39,226]\u001b[0m Trial 46 finished with value: 0.9589822335356893 and parameters: {'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:39,464]\u001b[0m Trial 47 finished with value: 0.9709313072316825 and parameters: {'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:39,634]\u001b[0m Trial 48 finished with value: 0.9527797059805615 and parameters: {'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:39,816]\u001b[0m Trial 49 finished with value: 0.9718502172022628 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:40,042]\u001b[0m Trial 50 finished with value: 0.9676028474674441 and parameters: {'min_samples_split': 8, 'min_samples_leaf': 12}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:40,259]\u001b[0m Trial 51 finished with value: 0.9745939062760707 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:40,424]\u001b[0m Trial 52 finished with value: 0.9741619298300281 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:40,667]\u001b[0m Trial 53 finished with value: 0.8533295367828465 and parameters: {'min_samples_split': 50, 'min_samples_leaf': 4}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:40,903]\u001b[0m Trial 54 finished with value: 0.9704124201403991 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:41,120]\u001b[0m Trial 55 finished with value: 0.9685763229883186 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:41,347]\u001b[0m Trial 56 finished with value: 0.9751126610929683 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:41,526]\u001b[0m Trial 57 finished with value: 0.8965240595570616 and parameters: {'min_samples_split': 32, 'min_samples_leaf': 7}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:41,776]\u001b[0m Trial 58 finished with value: 0.968993757538376 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:42,010]\u001b[0m Trial 59 finished with value: 0.8762949230119176 and parameters: {'min_samples_split': 41, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:42,349]\u001b[0m Trial 60 finished with value: 0.9239376480519227 and parameters: {'min_samples_split': 23, 'min_samples_leaf': 24}. Best is trial 41 with value: 0.9774722657465068.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:42,666]\u001b[0m Trial 61 finished with value: 0.9780288365148425 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:42,899]\u001b[0m Trial 62 finished with value: 0.9750998506352573 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:43,062]\u001b[0m Trial 63 finished with value: 0.9750624495507181 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:43,279]\u001b[0m Trial 64 finished with value: 0.9694697393078145 and parameters: {'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:43,473]\u001b[0m Trial 65 finished with value: 0.9618152781760009 and parameters: {'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:43,699]\u001b[0m Trial 66 finished with value: 0.972387147164669 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:43,887]\u001b[0m Trial 67 finished with value: 0.9689818830121404 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:44,089]\u001b[0m Trial 68 finished with value: 0.977061451850712 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:44,390]\u001b[0m Trial 69 finished with value: 0.9724035325330966 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:44,644]\u001b[0m Trial 70 finished with value: 0.9708631501900694 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:44,870]\u001b[0m Trial 71 finished with value: 0.9756406184393625 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:45,049]\u001b[0m Trial 72 finished with value: 0.9733135965377228 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:45,255]\u001b[0m Trial 73 finished with value: 0.9690301903194135 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:45,427]\u001b[0m Trial 74 finished with value: 0.9675745819355062 and parameters: {'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:45,645]\u001b[0m Trial 75 finished with value: 0.974117487559733 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:45,884]\u001b[0m Trial 76 finished with value: 0.9579218777998901 and parameters: {'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:46,089]\u001b[0m Trial 77 finished with value: 0.9685855268213656 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:46,289]\u001b[0m Trial 78 finished with value: 0.9694599125329966 and parameters: {'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:46,669]\u001b[0m Trial 79 finished with value: 0.9728553950559705 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:47,128]\u001b[0m Trial 80 finished with value: 0.9695014970827736 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:47,536]\u001b[0m Trial 81 finished with value: 0.9751323787250294 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:47,998]\u001b[0m Trial 82 finished with value: 0.9704421539665365 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:48,407]\u001b[0m Trial 83 finished with value: 0.9700764806695441 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:48,714]\u001b[0m Trial 84 finished with value: 0.9722085619109957 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 19}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:49,185]\u001b[0m Trial 85 finished with value: 0.9704446378960825 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:49,746]\u001b[0m Trial 86 finished with value: 0.9676168883969392 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:50,095]\u001b[0m Trial 87 finished with value: 0.9694528570506628 and parameters: {'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:50,317]\u001b[0m Trial 88 finished with value: 0.9721797343531148 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:50,588]\u001b[0m Trial 89 finished with value: 0.9579559573278337 and parameters: {'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:50,903]\u001b[0m Trial 90 finished with value: 0.9339404170471675 and parameters: {'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:51,249]\u001b[0m Trial 91 finished with value: 0.9755411582315952 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:51,602]\u001b[0m Trial 92 finished with value: 0.9737767454481263 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:52,013]\u001b[0m Trial 93 finished with value: 0.9719262243655654 and parameters: {'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:52,499]\u001b[0m Trial 94 finished with value: 0.9714044040080937 and parameters: {'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:52,983]\u001b[0m Trial 95 finished with value: 0.975160140463485 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:53,392]\u001b[0m Trial 96 finished with value: 0.9690881128489981 and parameters: {'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:54,005]\u001b[0m Trial 97 finished with value: 0.9689985751982351 and parameters: {'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:54,503]\u001b[0m Trial 98 finished with value: 0.9699472222033398 and parameters: {'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n",
            "\u001b[32m[I 2023-03-05 14:42:55,058]\u001b[0m Trial 99 finished with value: 0.9742109998651042 and parameters: {'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 61 with value: 0.9780288365148425.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'min_samples_split': 2, 'min_samples_leaf': 1}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.extmath import weighted_mode\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\",2,50)\n",
        "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\",1,30)\n",
        "    \n",
        "    clf = DecisionTreeClassifier(\n",
        "                                #criterion=criterion,\n",
        "                                #splitter=splitter,\n",
        "                                min_samples_split=min_samples_split,\n",
        "                                #max_depth=max_depth, \n",
        "                                #min_samples_leaf=min_samples_leaf, \n",
        "                                max_features=max_features\n",
        "                                )\n",
        "    clf.fit(X_train,y_train)\n",
        "    pred = clf.predict(X_valid)\n",
        "    return f1_score(pred,y_valid,average=\"weighted\")\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHNuGbxXTCb8"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "SL34sA7zJzYM",
        "outputId": "f6c2d580-5add-4009-f8b0-c4ff3a17c279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff8f92b81f0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results_val = []\n",
        "results_train = []\n",
        "x = np.linspace(1e-3,2,1000) #unico parametro que parece ser relevante????\n",
        "for i in x:\n",
        "  clf = GaussianNB(var_smoothing = i)\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred = clf.predict(X_valid)\n",
        "  results_val.append(f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  pred = clf.predict(X_train)\n",
        "  results_train.append(f1_score(pred,y_train,average=\"weighted\"))\n",
        "\n",
        "plt.plot(x,results_val,label='val')\n",
        "plt.plot(x,results_train,label='train')\n",
        "plt.ylabel(\"f1-score\")\n",
        "plt.xlabel(\"var_smoothing\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLM6ee3KShEL",
        "outputId": "902e3b78-e485-4957-e650-92daff7eef5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acuracia = 0.4074784276126558\n",
            "f1 0.5790190735694823\n",
            "recall 0.4074784276126558\n",
            "precision 1.0\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "clf = GaussianNB(var_smoothing = 1.225)\n",
        "clf.fit(X_train,y_train)\n",
        "print(\"acuracia =\",clf.score(X_valid,y_valid))\n",
        "\n",
        "pred = clf.predict(X_valid)\n",
        "print(\"f1\",f1_score(pred,y_valid,average=\"weighted\"))\n",
        "print(\"recall\",recall_score(pred,y_valid,average=\"weighted\"))\n",
        "print(\"precision\",precision_score(pred,y_valid,average=\"weighted\"))\n",
        "print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dME9UE5KWwP",
        "outputId": "4f3b61b4-1d1c-41ee-f0aa-bd1b8e5509b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 0.5821701553337219\n",
            "recall 0.410846028552266\n",
            "precision 0.9997128540868042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "check_test(clf,X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_PdH-nNS-tu"
      },
      "source": [
        "## Conclusão:\n",
        "**Podemos verificar no grafico acima, que o var_smoothing acima de 1.225 chega em um platô com o melhor resultado possivel de f1_score**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bEV8n_SjjVp"
      },
      "source": [
        "\n",
        "\n",
        "# LogisticRegression\n",
        "penalty = {l1, l2, elasticnet, None}\n",
        "\n",
        "dual= {True or False} Prefer dual=False when n_samples > n_features.\n",
        "\n",
        "tol = 1e-4\n",
        "\n",
        "C = 1.0\n",
        "\n",
        "fit_intercept = True\n",
        "\n",
        "intercept_scaling = 1\n",
        "\n",
        "class_weight = **dict** or ‘balanced’, default=None\n",
        "\n",
        "solver = {‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}\n",
        "For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; \n",
        "\n",
        "random_state = None **Used when solver == ‘sag’, ‘saga’**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY6AJS_bJon-"
      },
      "outputs": [],
      "source": [
        "def make_df_metrics(methods,results_train,results_val):\n",
        "  return pd.concat([pd.DataFrame({\"x\":methods,'y':results_train,'label':['train']*len(results_train)}),pd.DataFrame({\"x\":methods,'y':results_val,'label':['val']*len(results_val)})])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppcT59xxOAdD"
      },
      "source": [
        "### check penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFxxWK48StYy"
      },
      "outputs": [],
      "source": [
        "\n",
        "results_val = []\n",
        "results_train = []\n",
        "penalties = ['l1','l2',None]\n",
        "for penalty in penalties:\n",
        "  clf = Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(penalty=penalty,solver='saga',max_iter=10000))])\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred = clf.predict(X_valid)\n",
        "  results_val.append(f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  pred = clf.predict(X_train)\n",
        "  results_train.append(f1_score(pred,y_train,average=\"weighted\"))\n",
        "\n",
        "for l1_ratio in np.linspace(0.1,1.0,10):\n",
        "  penalties.append(f\"elasticnet_{l1_ratio}\")\n",
        "  clf = Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(penalty='elasticnet',solver='saga',l1_ratio=l1_ratio,max_iter=10000))])\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred = clf.predict(X_valid)\n",
        "  results_val.append(f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  pred = clf.predict(X_train)\n",
        "  results_train.append(f1_score(pred,y_train,average=\"weighted\"))\n",
        "\n",
        "df_metrics = make_df_metrics(penalties,results_train,results_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E6bLf48KLz1"
      },
      "outputs": [],
      "source": [
        "sns.barplot(data=df_metrics,y='x',x='y',hue='label')\n",
        "plt.ylabel(\"penalties\")\n",
        "plt.xlabel(\"f1_score\")\n",
        "plt.xlim(0.58, 0.66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbQC3S_4MKxY"
      },
      "outputs": [],
      "source": [
        "df_metrics.sort_values(by='y',ascending=False).groupby(by='label').head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnb2Zv6NN9HP"
      },
      "source": [
        "### check solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yVDWcPozAI9"
      },
      "outputs": [],
      "source": [
        "results_val = []\n",
        "results_train = []\n",
        "solvers = [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]\n",
        "for solver in solvers:\n",
        "  clf = Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(solver = solver,max_iter=10000,random_state=42))])\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred = clf.predict(X_valid)\n",
        "  results_val.append(f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  pred = clf.predict(X_train)\n",
        "  results_train.append(f1_score(pred,y_train,average=\"weighted\"))\n",
        "\n",
        "df_metrics = make_df_metrics(solvers,results_train,results_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-W3JCbcFfB0"
      },
      "outputs": [],
      "source": [
        "sns.barplot(data=df_metrics,y='x',x='y',hue='label')\n",
        "plt.ylabel(\"solver\")\n",
        "plt.xlabel(\"f1_score\")\n",
        "plt.xlim(0.62, 0.66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6Vw4NpdNv17"
      },
      "outputs": [],
      "source": [
        "df_metrics.sort_values(by='y',ascending=False).groupby(by='label').head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVBYlQWuMho2"
      },
      "outputs": [],
      "source": [
        "def plot_line(x,results_val,results_train,xlabel):\n",
        "  plt.title(\"testing for \"+xlabel)\n",
        "  plt.plot(Cs,results_val,label='val')\n",
        "  plt.plot(Cs,results_train,label='train')\n",
        "  plt.ylabel(\"f1-score\")\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUN8gVo9N61N"
      },
      "source": [
        "### check C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4Xvh7Oin5GK"
      },
      "outputs": [],
      "source": [
        "results_val = []\n",
        "results_train = []\n",
        "Cs = np.linspace(0.05,7.5,200)\n",
        "for C in Cs:\n",
        "  clf = Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(max_iter=10000,C=C))])\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred = clf.predict(X_valid)\n",
        "  results_val.append(f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  pred = clf.predict(X_train)\n",
        "  results_train.append(f1_score(pred,y_train,average=\"weighted\"))\n",
        "\n",
        "df_metrics = make_df_metrics(Cs,results_train,results_val)\n",
        "\n",
        "plot_line(Cs,results_val,results_train,\"C\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AuAo5h8LmCO"
      },
      "outputs": [],
      "source": [
        "df_metrics.sort_values(by='y',ascending=False).groupby(by='label').head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pttwvqIRN4En"
      },
      "source": [
        "### Check tol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36uQ6t2f3TtY"
      },
      "outputs": [],
      "source": [
        "results_val = []\n",
        "results_train = []\n",
        "tols = np.linspace(0.00001,1.0,200)\n",
        "for tol in tols:\n",
        "  clf = Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(max_iter=10000,tol=tol))])\n",
        "  clf.fit(X_train,y_train)\n",
        "  pred = clf.predict(X_valid)\n",
        "  results_val.append(f1_score(pred,y_valid,average=\"weighted\"))\n",
        "  pred = clf.predict(X_train)\n",
        "  results_train.append(f1_score(pred,y_train,average=\"weighted\"))\n",
        "    \n",
        "df_metrics = make_df_metrics(tols,results_train,results_val)\n",
        "\n",
        "plot_line(tols,results_val,results_train,\"tol\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7Td-o4z9USi"
      },
      "outputs": [],
      "source": [
        "df_metrics.sort_values(by='y',ascending=False).groupby(by='label').head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Yp_3EUOFF3"
      },
      "outputs": [],
      "source": [
        "clf =  Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression(penalty='l2',solver='newton-cholesky',C=0.5,tol=5.5,max_iter=10000))])\n",
        "clf.fit(X_train,y_train)\n",
        "pred = clf.predict(X_valid)\n",
        "print(\"f1_val\",f1_score(pred,y_valid,average=\"weighted\"))\n",
        "pred = clf.predict(X_train)\n",
        "print(\"f1_train\",f1_score(pred,y_train,average=\"weighted\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_IbvesIOLCH"
      },
      "outputs": [],
      "source": [
        "check_test(clf,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnxdNy7VOaRC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
